# Traitement Big Data pour la reconnaissance dâ€™images de fruits ğŸğŸŒğŸ‡

**Projet OpenClassrooms IngÃ©nieur IA - P11**  
**Auteur : CÃ©cile MAYER**  
**Date : AoÃ»t 2025**  

---

## ğŸ“Œ Objectif du projet

Ce projet vise Ã  **mettre en place une architecture Big Data** pour la reconnaissance dâ€™images de fruits, capable de **supporter un passage Ã  lâ€™Ã©chelle**. Il sâ€™inscrit dans le cadre dâ€™un POC pour lâ€™entreprise fictive *Fruits!*, une start-up AgriTech dÃ©veloppant des outils de reconnaissance visuelle de fruits, notamment Ã  travers une future application mobile grand public.

---

## ğŸ§± DÃ©marche et mÃ©thodologie

Ce travail repose sur la **reprise, lâ€™adaptation et lâ€™optimisation** dâ€™un notebook initial, conÃ§u pour un environnement Big Data. La dÃ©marche suit une logique progressive :

### 1. ğŸ“¥ Chargement & prÃ©paration des donnÃ©es
- DonnÃ©es image (Kaggle fruits-360) prÃ©-organisÃ©es en `train/` et `test/` (~140 000 images)
- Extraction des labels depuis les chemins
- Partitionnement intelligent des donnÃ©es pour le calcul distribuÃ©

### 2. ğŸ§  Extraction de features via MobileNetV2
- Suppression de la couche finale du modÃ¨le (`include_top=False`)
- Diffusion des poids du modÃ¨le avec `sc.broadcast()` pour chaque worker Spark avec instanciation unique locale du modÃ¨le
- Traitement batch dâ€™images avec `UDF` dans Spark

### 3. âš™ï¸ RÃ©duction de dimension par PCA
- Standardisation des vecteurs
- Calcul du nombre optimal de composantes expliquant â‰¥ 90% de la variance
- Application de la PCA sur `train` et `test` avec les mÃªmes transformations

### 4. â˜ï¸ Passage Ã  lâ€™Ã©chelle sur AWS EMR
- Tests locaux : 1 000 Ã  5 000 images
- DÃ©ploiement sur EMR avec JupyterHub (mode interactif) et Spark-submit (mode client puis cluster)
- Ã‰valuation du temps de traitement, scalabilitÃ©
- Adaptation du nombre de workers et de partitions pour optimiser les performances

### 5. âœ¨ Bonus - Mise en oeuvre d'un algorithme de classification
- Test de rÃ©gression logistique, RandomForrest, GradientBoosting
- MÃ©triques globales, par classes
- Focus sur les catÃ©gories mal classÃ©es (matrice de confusion, TSNE)
---

## ğŸ—ï¸ Infrastructure Big Data

- **Stockage :** S3 (`s3://ociae-p11`)
- **Traitement distribuÃ© :** AWS EMR (cluster Spark)
- **Visualisation & suivi par SSH et/ou tunneling SSH:**
  - Spark UI (ports 18080 / 20888)
  - JupyterHub (port 9443)
- **Traitement batch final :** `spark-submit` (mode client/cluster)

---

## ğŸ“ Structure du dÃ©pÃ´t

```
.
â”œâ”€â”€gitlab-ci.yml            # Script de dÃ©ploiement/run depuis Gitlab
â”œâ”€â”€ p11_app.py              # Script principal PySpark optimisÃ©
â”œâ”€â”€ run_p11.sh              # Script d'exÃ©cution (Spark-submit)
â”œâ”€â”€emr_config.json          # Configuration EMR (accÃ¨s s3)
â”œâ”€â”€bootstrap-emr.sh         # Script d'amorÃ§age du cluster 
â”œâ”€â”€ p11_optimisÃ©_local.ipynb    # Notebook de traitement local
â”œâ”€â”€ p11_optimisÃ©_EMR.ipynb      # Notebook EMR / JupyterHub
â”œâ”€â”€ p11_classification.ipynb    # DÃ©buts de tests de classification
â”œâ”€â”€ P8_Notebook_Linux_EMR_PySpark_V1.0.ipynb  # Notebook original Ã  reprendre
â””â”€â”€ P8_Notebook_Linux_EMR_PySpark_V2.0 (PCA).ipynb  # Notebook original avec rÃ©duction PCA
â”œâ”€â”€Dockerfile               # Conteneur pour l'exÃ©cution locale
â”œâ”€â”€docker-compose.yml       # Ajout de services au docker local

```


---

## ğŸš€ ExÃ©cution du script sur EMR

### PrÃ©-requis :
- Un cluster EMR actif avec Spark
- DonnÃ©es accessibles sur S3 (`s3://ociae-p11/images/`)

### Modes d'exÃ©cution :

- â–¶ï¸ **Via GitLab CI/CD**   
  Utilise le fichier [`ğŸŸ¡ .gitlab-ci.yml`](.gitlab-ci.yml) pour lancer automatiquement le traitement Big Data aprÃ¨s chaque push.

- ğŸ–¥ï¸ **En ligne de commande via SSH**  
  ExÃ©cution manuelle avec [`ğŸŸ¢ run_p11.sh`](./run_p11.sh), en mode client ou cluster.

Les rÃ©sultats sont sauvegardÃ©s en format Parquet dans :
- `s3://ociae-p11/results_train`
- `s3://ociae-p11/results`

---

## ğŸ§ª RÃ©sultats clÃ©s

| Mode                | Volume     | Workers | Partitions | Temps approx. |
|---------------------|------------|---------|------------|----------------|
| Local               | 1 000 img  | N/A     | 10         | ~50 sec        |
| EMR JupyterHub      | 1 000 img  | 5       | 10         | ~1 min         |
| EMR Spark-submit    | 50 000 img | 5 â†’ 8   | 100        | ~7 min 30      |
| EMR Spark-submit    | 103 993 img| 8       | 200        | ~13 min        |

---

## âœ… Points forts techniques

- ğŸ’¡ Optimisation mÃ©moire : `model_instance` instanciÃ© une fois par worker
- ğŸ”„ Mise en cache stratÃ©gique (`.cache()`) des DataFrames
- ğŸ“¦ Broadcast des poids du modÃ¨le pour Ã©viter les surcharges
- ğŸ“Š RÃ©duction de dimension dynamique (PCA â‰¥ 90% de variance)
- â˜ï¸ Traitement scalable et industrialisable (via `spark-submit`)

---

## ğŸ“Œ Perspectives

- AmÃ©lioration du classifieur en aval (boosting, fine-tuning)
- Affinage de la rÃ©duction de dimension (t-SNE, UMAP ?)
- IntÃ©gration future dans une API ou une application mobile

---

## ğŸ” Respect du RGPD

- Traitements rÃ©alisÃ©s dans des clusters situÃ©s sur le territoire europÃ©en
- Pas de stockage local de donnÃ©es personnelles
- Instance EMR maintenue active uniquement pour les tests/dÃ©mos

---

## ğŸ“½ï¸ PrÃ©sentation du projet

[ğŸ‘‰ AccÃ©der Ã  la prÃ©sentation de synthÃ¨se (OneDrive)](https://1drv.ms/p/c/08F813C23A12D604/EXtK3sqeYFVMphQhEuaSfAYBH4BfFI8xSb7vYOU6vY40AQ?e=IqaUex)

Ce document utilisÃ© en soutenance aborde :
- L'architecture choisie
- Le processus de traitement
- Les rÃ©sultats obtenus
- Des pistes d'amÃ©lioration

---

## ğŸ” AccÃ¨s au bucket S3 (lecture seule)

Un utilisateur IAM nommÃ© `s3-readonly` a Ã©tÃ© configurÃ© avec les permissions minimales pour accÃ©der aux buckets S3 `ociae-p11` et de logs EMR.

ğŸ‘¤ **AccÃ¨s AWS Console â€“ Projet P11**

- **URL de connexion :** https://908027391515.signin.aws.amazon.com/console
- **Nom dâ€™utilisateur :** s3-readonly
- **Mot de passe temporaire :** OC-aie#11

â¡ï¸ Vous devrez dÃ©finir votre propre mot de passe lors de la premiÃ¨re connexion.

Vous aurez accÃ¨s en lecture seule au bucket `s3://ociae-p11` (par la console ou lâ€™interface S3).


Pour toute question, nâ€™hÃ©sitez pas Ã  me contacter !  
ğŸšœğŸ *Fruits! pour la planÃ¨te... et le cloud.* â˜ï¸ğŸŒ±
